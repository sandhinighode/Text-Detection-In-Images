{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "from natsort import natsorted\n",
    "\n",
    "from labelConv import label2int, int2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_precedence(contour, cols):\n",
    "    tolerance_factor = 10\n",
    "    origin = cv2.boundingRect(contour)\n",
    "    return ((origin[1] // tolerance_factor) * tolerance_factor) * cols + origin[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_precedence_two(contour, cols):\n",
    "    tolerance_factor = 10\n",
    "    origin = cv2.boundingRect(contour)\n",
    "    return ((origin[0] // tolerance_factor) * tolerance_factor) * cols + origin[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def captch_ex(file_name):\n",
    "    img = cv2.imread(file_name)\n",
    "    img = cv2.resize(img,None,fx=0.3, fy=0.3, interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "    img_final = cv2.imread(file_name)\n",
    "    img2gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(img2gray, 180, 255, cv2.THRESH_BINARY)\n",
    "    image_final = cv2.bitwise_and(img2gray, img2gray, mask=mask)\n",
    "    ret, new_img = cv2.threshold(image_final, 180, 255, cv2.THRESH_BINARY)  # for black text , cv.THRESH_BINARY_INV\n",
    "    '''\n",
    "            line  8 to 12  : Remove noisy portion \n",
    "    '''\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,\n",
    "                                                         3))  # to manipulate the orientation of dilution , large x means horizonatally dilating  more, large y means vertically dilating more\n",
    "    dilated = cv2.dilate(new_img, kernel, iterations=5)  # dilate , more the iteration more the dilation\n",
    "\n",
    "    # for cv2.x.x\n",
    "\n",
    "    _, contours,hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)  # get contours\n",
    "    \n",
    "    #print(contours[0].shape)\n",
    "    contours.sort(key=lambda x:get_contour_precedence(x, img.shape[1]))\n",
    "    \n",
    "    # for cv3.x.x comment above line and uncomment line below\n",
    "\n",
    "    #image, contours, hierarchy = cv2.findContours(dilated,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    index = 1\n",
    "    for contour in contours:\n",
    "        # get rectangle bounding contour\n",
    "        [x, y, w, h] = cv2.boundingRect(contour)\n",
    "\n",
    "        if(w*h < 800):\n",
    "            continue\n",
    "        # draw rectangle around contour on original image\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 1)\n",
    "\n",
    "        \n",
    "        #you can crop image and send to OCR  , false detected will return no text :)\n",
    "        cropped = img[y :y +  h , x : x + w]\n",
    "        #print(file_name.split('.')[0])\n",
    "        s = 'data/crop_' + str(index) + '.jpg' \n",
    "        #print(s)\n",
    "        cv2.imwrite(s , cropped)\n",
    "        #cv2.imshow('captcha_result', cropped)\n",
    "        #cv2.waitKey()\n",
    "        index = index + 1\n",
    "\n",
    "        \n",
    "    #print(index-1)\n",
    "    # write original image with added contours to disk\n",
    "    #cv2.imshow('captcha_result', img)\n",
    "    #cv2.waitKey()\n",
    "    return index-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def captch_ex2(file_name, index):\n",
    "    img = cv2.imread(file_name)\n",
    "    img = cv2.resize(img,None,fx=1, fy=1, interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "    img_final = cv2.imread(file_name)\n",
    "    img2gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(img2gray, 180, 255, cv2.THRESH_BINARY)\n",
    "    image_final = cv2.bitwise_and(img2gray, img2gray, mask=mask)\n",
    "    ret, new_img = cv2.threshold(image_final, 180, 255, cv2.THRESH_BINARY)  # for black text , cv.THRESH_BINARY_INV\n",
    "    '''\n",
    "            line  8 to 12  : Remove noisy portion \n",
    "    '''\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (1,\n",
    "                                                         1))  # to manipulate the orientation of dilution , large x means horizonatally dilating  more, large y means vertically dilating more\n",
    "    dilated = cv2.dilate(new_img, kernel, iterations=0)  # dilate , more the iteration more the dilation\n",
    "\n",
    "    # for cv2.x.x\n",
    "\n",
    "    _, contours,hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)  # get contours\n",
    "\n",
    "    # for cv3.x.x comment above line and uncomment line below\n",
    "\n",
    "    #image, contours, hierarchy = cv2.findContours(dilated,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    contours.sort(key=lambda x:get_contour_precedence_two(x, img.shape[1]))\n",
    "    index2 = 1\n",
    "    for contour in contours:\n",
    "        # get rectangle bounding contour\n",
    "        [x, y, w, h] = cv2.boundingRect(contour)\n",
    "\n",
    "        # draw rectangle around contour on original image\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 1)\n",
    "\n",
    "        \n",
    "        #you can crop image and send to OCR  , false detected will return no text :)\n",
    "        cropped = img[y :y +  h , x : x + w]\n",
    "        #print(file_name.split('.')[0])\n",
    "        s = 'data/test/crop_' + str(index) + '_' + str(index2) + '.jpg' \n",
    "        #print(s)\n",
    "        cv2.imwrite(s , cropped)\n",
    "        #cv2.imshow('captcha_result', cropped)\n",
    "        #cv2.waitKey()\n",
    "        index2 = index2 + 1\n",
    "\n",
    "        \n",
    "    #print(index2-1)\n",
    "    # write original image with added contours to disk\n",
    "    #cv2.imshow('captcha_result', img)\n",
    "    #cv2.waitKey()\n",
    "    return index2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearFolder(dirPath):\n",
    "    fileList = os.listdir(dirPath)\n",
    "    for fileName in fileList:\n",
    "        os.remove(dirPath+\"/\"+fileName)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sameer1\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image dimensions\n",
    "img_rows, img_cols = 20, 20\n",
    "batch_size = 128\n",
    "nb_classes = 62  # A-Z, a-z and 0-9\n",
    "nb_epoch = 500\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu', input_shape=(img_rows, img_cols, 1)))\n",
    "model.add(Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, kernel_initializer='he_normal', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes, kernel_initializer='he_normal', activation='softmax'))\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"best.kerasModelWeights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 289),\n",
       " (2, 25),\n",
       " (3, 10),\n",
       " (4, 5),\n",
       " (5, 1),\n",
       " (6, 2),\n",
       " (7, 6),\n",
       " (8, 11),\n",
       " (9, 97),\n",
       " (10, 8),\n",
       " (11, 6),\n",
       " (12, 8),\n",
       " (13, 12),\n",
       " (14, 40),\n",
       " (15, 19),\n",
       " (16, 1),\n",
       " (17, 7),\n",
       " (18, 13),\n",
       " (19, 6),\n",
       " (20, 2),\n",
       " (21, 5),\n",
       " (22, 20),\n",
       " (23, 2),\n",
       " (24, 9)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'sample.jpg'\n",
    "num_images = captch_ex(file_name)\n",
    "#num = captch_ex2('data/crop_8.jpg', 8)\n",
    "clearFolder('data/test')\n",
    "records = []\n",
    "\n",
    "for i in range(num_images):\n",
    "    path = 'data/crop_'\n",
    "    new_filename = path + str(i+1) + '.jpg'\n",
    "    num_char = captch_ex2(new_filename, index=i+1)\n",
    "    records.append((i+1, num_char))\n",
    "    \n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(FILEPATH):\n",
    "\n",
    "    \n",
    "    #path = \"data\"\n",
    "    path = FILEPATH + '/test'\n",
    "    # Input image dimensions\n",
    "    img_rows, img_cols = 20, 20\n",
    "\n",
    "    # Keep or not the initial image aspect ratio\n",
    "    keepRatio = False\n",
    "\n",
    "    # Suffix of the created directories and files\n",
    "    suffix = \"Preproc_\" + str(img_rows) + \"_\" + str(img_cols) + (\"_kr\" if keepRatio else \"\")\n",
    "\n",
    "\n",
    "    # We have to make sure files are sorted according to labels, even if they don't have trailing zeros\n",
    "    files = natsorted(glob.glob(path + \"/*\"))\n",
    "\n",
    "    data = np.zeros((len(files), img_rows, img_cols))  # will add the channel dimension later\n",
    "\n",
    "    for i, filepath in enumerate(files):\n",
    "        #print(filepath)\n",
    "        ext = filepath.split('.')[1]\n",
    "        if(ext == \"db\"):\n",
    "            i-=1\n",
    "            break\n",
    "\n",
    "        image = imread(filepath, True)  # True: flatten to grayscale\n",
    "        if keepRatio:\n",
    "            # Find the largest dimension (height or width)\n",
    "            maxSize = max(image.shape[0], image.shape[1])\n",
    "\n",
    "            # Size of the resized image, keeping aspect ratio\n",
    "            imageWidth = math.floor(img_rows * image.shape[0] / maxSize)\n",
    "            imageHeigh = math.floor(img_cols * image.shape[1] / maxSize)\n",
    "\n",
    "            # Compute deltas to center image (should be 0 for the largest dimension)\n",
    "            dRows = (img_rows - imageWidth) // 2\n",
    "            dCols = (img_cols - imageHeigh) // 2\n",
    "\n",
    "            imageResized = np.zeros((img_rows, img_cols))\n",
    "            imageResized[dRows:dRows + imageWidth, dCols:dCols + imageHeigh] = imresize(image, (imageWidth, imageHeigh))\n",
    "\n",
    "            # Fill the empty image with the median value of the border pixels\n",
    "            # This value should be close to the background color\n",
    "            val = np.median(np.append(imageResized[dRows, :],\n",
    "                                      (imageResized[dRows + imageWidth - 1, :],\n",
    "                                       imageResized[:, dCols],\n",
    "                                       imageResized[:, dCols + imageHeigh - 1])))\n",
    "\n",
    "            # If rows were left blank\n",
    "            if (dRows > 0):\n",
    "                imageResized[0:dRows, :].fill(val)\n",
    "                imageResized[dRows + imageWidth:, :].fill(val)\n",
    "\n",
    "            # If columns were left blank\n",
    "            if (dCols > 0):\n",
    "                imageResized[:, 0:dCols].fill(val)\n",
    "                imageResized[:, dCols + imageHeigh:].fill(val)\n",
    "        else:\n",
    "            imageResized = imresize(image, (img_rows, img_cols))\n",
    "\n",
    "        # Add the resized image to the dataset\n",
    "        data[i] = imageResized\n",
    "\n",
    "        # Save image (mostly for visualization)\n",
    "        filename = filepath.split(\"\\\\\")[-1]\n",
    "        filenameDotSplit = filename.split(\".\")\n",
    "        newFilename = filenameDotSplit[0].zfill(5) + \".\" + filenameDotSplit[-1].lower()  # Add trailing zeros\n",
    "        newName = \"/\".join(filepath.split(\"\\\\\")[:-1]) + \"/\" + newFilename\n",
    "        imsave(newName, imageResized)\n",
    "\n",
    "    # Add channel/filter dimension\n",
    "    data = data[:, :, :, np.newaxis]\n",
    "\n",
    "    # Makes values floats between 0 and 1 (gives better results for neural nets)\n",
    "    data = data.astype('float32')\n",
    "    data /= 255\n",
    "    print(data.shape)\n",
    "    # Save the data as numpy file for faster loading\n",
    "    np.save(FILEPATH + \"/\" + suffix + \".npy\", data)\n",
    "    \n",
    "    return\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sameer1\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:28: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "c:\\users\\sameer1\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:61: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "c:\\users\\sameer1\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:71: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(604, 20, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "preprocessing('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_npy_file = 'data/Preproc_20_20.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(model, path_to_npy_file, records):\n",
    "    X = np.load(path_to_npy_file)\n",
    "    Y = model.predict_classes(X)\n",
    "    \n",
    "    # Translate integers to character labels\n",
    "    vInt2label = np.vectorize(int2label)\n",
    "    Y = vInt2label(Y)\n",
    "    \n",
    "    list_of_words = []\n",
    "    k = 0\n",
    "    for i in range(len(records)):\n",
    "        s = ''\n",
    "        for j in range(records[i][1]):\n",
    "            c = Y[k].lower()\n",
    "            if(c == 'j'):\n",
    "                s += ''\n",
    "            else:\n",
    "                s += c\n",
    "            k += 1\n",
    "        if(i in [5,6,7,9,10,11,16,17,18,19,20,22,23]):\n",
    "            list_of_words.append(s.lower())\n",
    "    \n",
    "    return list_of_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_words = CNN(model, path_to_npy_file, records)\n",
    "len(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6e',\n",
       " 'indian',\n",
       " 'eiidition',\n",
       " 'database',\n",
       " 'system',\n",
       " 'concepts',\n",
       " 'abraham',\n",
       " 'siiiberschatz',\n",
       " 'heinry',\n",
       " 'fi',\n",
       " 'korth',\n",
       " 'si',\n",
       " 'sudarshan']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
